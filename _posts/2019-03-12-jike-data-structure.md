---
layout: post
title: "极客时间《数据结构与算法之美》笔记"
categories: notes
---

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [数组](#数组)
- [链表](#链表)
  - [单链表](#单链表)
  - [循环链表](#循环链表)
  - [双向链表](#双向链表)
  - [双向循环链表](#双向循环链表)
- [排序](#排序)
  - [如何分析一个排序算法](#如何分析一个排序算法)
  - [插入排序、冒泡排序、选择排序](#插入排序-冒泡排序-选择排序)
- [跳表](#跳表)
- [散列表](#散列表)
  - [散列函数](#散列函数)
  - [散列冲突](#散列冲突)
    - [开放寻址法](#开放寻址法)
    - [链表法](#链表法)
    - [散列冲突解决方法的选择](#散列冲突解决方法的选择)
  - [高效扩容散列表](#高效扩容散列表)
  - [工业级散列表分析（Java的HashMap）](#工业级散列表分析java的hashmap)
  - [散列表和链表的组合](#散列表和链表的组合)
- [散列算法](#散列算法)
  - [常用算法](#常用算法)
  - [应用](#应用)
- [树](#树)
  - [说明](#说明)
  - [二叉树](#二叉树)
    - [二叉查找树](#二叉查找树)
    - [有了高效的散列表，为什么还需要二叉树](#有了高效的散列表为什么还需要二叉树)
- [动态规划](#动态规划)

<!-- /code_chunk_output -->

# 数组

**线性表**（Linear List）就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

与它相对立的概念是**非线性表**，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

数组有**随机访问**的特性，

以⼀个长度为10的int类型的数组int[] a = new int[10]来举例。在我画的这个图中，计算机给数组a[10]，分配了一块连续内 存空间1000～1039，其中，内存块的首地址为base_address = 1000。每个元素存储的内存地址: 
```c
a[i]_address = base_address + i * data_type_size
```

所以根据下标 i 就很容易知道内存地址，从而访问的时间复杂度为O(1)。但是为了保持内存数据的连续性，插入、删除这两个操作比较低效。如果在数组中间插入数据，那么中间到后面的数据都得依次移后一位，最坏时间复杂度是O(n)
删除也一样，最坏时间复杂度是O(n)，如果删除最后一位数据，时间复杂度则是O(1)。

**删除的优化:** 为了避免删除多个元素，导致搬移多次。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

<br/>

# 链表

## 单链表

数组需要一块连续的内存空间来存储，但是链表相反，不需要一块连续的内存空间，是通过指针将一组零散的内存块串联在一起。这里把内存块成为链表的**结点**，结点除了存储数据外，还带有一个**指针next**指向下一个结点的地址。单链表的第一个结点叫作**头结点**，最后一个结点叫作**尾结点**，尾结点的指针指向一个空地址NULL。

插入和删除对应时间复杂度是O(1)，因为只需要改变相邻结点的指针。

查找的时间复杂度是O(n)，因为内存空间不连续，无法通过寻址公式计算出对应的内存地址，只能通过指针一个结点一个结点依次遍历，直到找到相应的结点。

## 循环链表

循环链表是一种特殊的单链表，和单链表的区别是循环链表的尾结点指针是指向链表的头结点。

## 双向链表

和单链表的区别是每个结点还有一个**指针prev**指向前⾯的结点。    

## 双向循环链表

循环链表和双向链表二者结合。

<br/>

# 排序

## 如何分析一个排序算法

- 排序算法的执行效率:  最好情况、最坏情况、平均情况时间复杂度；时间复杂度的系数、常数 、低阶；比较次数和交换（或移动）次数。

- 排序算法的内存消耗:  是否原地排序。即是否只在原数组里排序，不需要创建新的空间。

- 排序算法的稳定性:  如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

## 插入排序、冒泡排序、选择排序

**冒泡排序算法** 是原地排序，空间复杂度为O(1)，稳定的排序算法，最好的情况是数据已经是有序的，时间复杂度是O(n)，最坏的情况是数据是倒序排列，时间复杂度是O(n^2)。

**插入排序算法** 和 冒泡排序算法 一样。

**选择排序算法** 原地排序、稳定的排序算法，最好和最坏的情况的时间复杂度是O(n^2)。

<br/>

# 跳表

只需要对链表稍加改造，就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫作**跳表**。

对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是O(n)。

每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作索引或索引层，下图建立了两级索引。假如需要检索出结点 10，则先从第二级索引里遍历到结点 7 ，然后发现下个结点是 13 ，则往下级索引结点 7 继续遍历，然后一直遍历到节点 9 ，发现下个结点是 13，则往原始链表结点 9 继续遍历，遍历一次就能发现结点 10。**这种链表加多级索引的结构，就是跳表。时间复杂度为O(logn)。跳表是空间换时间，索引层越多，额外占用空间越大。**

![](/images/492206afe5e2fef9f683c7cff83afa65.jpg)

往跳表中插入数据时，如果仅仅插入到原始链表中，不更新索引，就有可能出现某2个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。

类似红黑树、AVL树这样的平衡二叉树通过左右旋的方式保持左右子树的大小平衡。**为了维护跳表的平衡性，插入数据不仅要插入到原始链表中，也得插入到索引中。**

<br/>

# 散列表

**散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果 没有数组，就没有散列表。**

**散列表的查询效率并不能笼统地说成是O(1)**。它跟散列函数、装载因子、散列冲突等都有关系。

通过散列函数把元素的键值映射为下标（即散列值），然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。

## 散列函数

输入值转化为数组下标的映射方法就叫作**散列函数**（Hash函数、哈希函数），而散列函数计算得到的值就叫作**散列值** （Hash值、哈希值）。

**散列函数的设计不能太复杂**。过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能。其次，**散列函数⽣成的值要尽可能随机并且均匀分布**，这样才能避免或者最小化散列冲突。

## 散列冲突

散列函数计算得到的散列值是一个非负整数。相同的key，经过散列函数得到的散列值也应该是相同的。
而不相同的key，经过散列函数得到的散列值如果相同，那么就是散列冲突。

常用的散列冲突解决方法有两类，**开放寻址法** （open addressing）和 **链表法**（chaining）。链表法是比较常用。

### 开放寻址法

不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。

散列表的**装载因子** = 填入表中的元素个数 / 散列表的长度

装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

**线性探测:**

当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止，这种方法叫线性探测。

在散列表中查找元素的过程中，如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

**删除元素时，会特殊标记为deleted**，当线性探测查找的时候，遇到标记为deleted的空间，并不是停下来，而是继续往下探测。

缺点: 当散列表中插入的数据越来越多时，散列冲突发⽣的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为O(n)。

**二次探测:**

二次探测，跟线性探测很像，线性探测每次探测的步长是1，那它探测的下标序列就是线性探测步长的“二次方”。

**双重散列:**

先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

### 链表法

在散列表中，元素被称为“桶 （bucket）”或者“槽（slot）”，而每个桶或者槽会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。

### 散列冲突解决方法的选择

Java中LinkedHashMap就采用了链表法解决冲突，ThreadLocalMap是通过线性探测的开放寻址法来解决冲突。

当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是Java中的ThreadLocalMap使用开 放寻址法解决散列冲突的原因。

基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加 灵活，支持更多的优化策略，比如用红黑树代替链表。

## 高效扩容散列表

针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。

**操作如下:**

- 当装载因子触达阈值之后， 我们只申请新空间，但并不将老的数据搬移到新散列表中。
- 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。
- 每次插入一个数据 到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。
- 对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式， 任何情况下，插入一个数据的时间复杂度都是O(1)。

## 工业级散列表分析（Java的HashMap） 

1. 初始大小: HashMap默认的初始大小是16，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高HashMap的性能。

2. 装载因子和动态扩容: 最大装载因子默认是0.75，当HashMap中元素个数超过 0.75 * capacity（capacity表示散列表的容量）的时候，就会启动扩容， 每次扩容都会扩容为原来的两倍大小。

3. 散列冲突解决方法: HashMap底层采用链表法来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现 拉链过长，则会严重影响HashMap的性能。 于是，在JDK1.8版本中，为了对HashMap做进一步优化，我们引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树。我们可以利用红黑树快速增删改查的特点，提高HashMap的性能。当红黑树结点个数少于8个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。 

4. 散列函数: 散列函数的设计并不复杂，追求的是简单高效、分布均匀。
   
    ```java
    int hash(Object key) { // hash 函数
        int h = key.hashCode()； 
        return (h ^ (h >>> 16)) & (capitity -1); //capicity 表示散列表的大小 
    }
    ```
    
    ```java
    public int hashCode() {  // 如 String 类型的对象的 hashCode()
        int var1 = this.hash; 
        if (var1 == 0 && this.value.length > 0) { 
            char[] var2 = this.value; 
            for (int var3 = 0; var3 < this.value.length; ++var3) { 
                var1 = 31 * var1 + var2[var3]; 
            }
            this.hash = var1; 
        }
        return var1; 
    }
    ```

## 散列表和链表的组合

**LRU缓存淘汰算法** 和 Java 的 **LinkedHashMap** 都是通过链表和散列表这两种数据结构组合实现的。

# 散列算法

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是**哈希算法**，而通过原始数据映射之后得到的二进制值串就是哈希值。

## 常用算法

- MD5 (Message-Digest Algorithm): 

- SHA (Secure Hash Algorithm): 

## 应用

- 安全加密:  密码加密。

- 唯一标识:  例如要在海量的图库中，搜索一张图是否存在，用哈希算法计算出其唯一标识值。

- 数据校验: 下载文件后，需要校验是否不完整或者被篡改了。

- 散列函数: 散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，除此之外，散列函数执行的快慢，也会影响散列表的性能。

- 负载均衡: 对客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 

- 数据分片: 与负载均衡类似。

- 分布式存储: 与负载均衡类似。

# 树

## 说明

没有父节点的节点叫作**根节点**，没有子节点的节点叫作**叶子节点**或者**叶节点**。

节点的**高度** = 节点到叶子节点的最长路径（边数）
节点的**深度** = 根节点到这个节点所经历的边的个数
节点的**层数** = 节点的深度 + 1
**树的高度** = 根节点的高度

## 二叉树

每个节点都有左右两个子节点，这种二叉树就叫作**满二叉树**。

叶子节点都在最底下两层，<u>最后一层的叶子节点都靠左排列</u>，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作**完全二叉树**。

存储一棵二叉树，一种是基于指针或者引用的**二叉链式存储法**，是指每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针；一种是基于数组的**顺序存储法**，文字不好描述，直接看下图，下标为0的位置不存储。

![](/images/08bd43991561ceeb76679fbb77071223.jpg)

二叉树的遍历有三种: 

- **前序遍历**是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。（上左右）

- **中序遍历**是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。（左上右）

- **后序遍历**是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。（左右上）

![](/images/ab103822e75b5b15c615b68560cb2416.jpg)

二叉树遍历的时间复杂度是O(n)。

### 二叉查找树

也叫二叉搜索树和二叉排序树。

在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

**查找:** 从根节点开始查，小则从左子节点查，否则右子节点查。

**插入:** 前面的操作和查找的步骤一致，最后遍历到叶子节点后，插入的数值比叶子节点小则插入在左子节点，否则插入在右子节点。即不会改变原节点的位置。

正因为不改动原节点位置，所以最差情况是退化成链表，时间复杂度为O(n)，如果是一棵完全二叉树（或满二叉树），那么时间复杂度跟树的高度成正比，也就是**O(height)**，即**O(logn)**。

**删除:** 有两种，一种是直接删除节点，有可能会影响其它节点的位置改动，一种是直接标志为已删除，所有节点位置不需要改变。

也叫**二叉排序树**的原因是中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是O(n)。

### 有了高效的散列表，为什么还需要二叉树

- 散列表中的数据是无序存储的，二叉查找树只需要中序遍历，就可以在O(n)的时间复杂度内，输出有序的数据序列。

- 散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在O(logn)。

- 散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比logn小，所以实际的查找速度可能不一定比O(logn)快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。

- 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。

# 动态规划

